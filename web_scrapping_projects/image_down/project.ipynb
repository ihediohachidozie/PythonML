{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3890ef9-6d5e-448e-a30c-646c06d32cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97761a54-b2a1-439b-aab0-7a3a4b19b441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_map = requests.get('https://www.pngmart.com/sitemap.xml')\n",
    "soup = BeautifulSoup(site_map.text, \"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961bc14e-a884-4ac3-918a-081bb94e7f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls = [url.text for url in soup.find_all('loc')]\n",
    "page_urls = [url for url in urls if 'posts' in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf8eddb-076a-4aae-8572-859a2ce1215e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = []\n",
    "# loop through the list of xml pages\n",
    "for page in page_urls[0:1]:\n",
    "    get_xml_page = requests.get(page) # goto the xml page\n",
    "    soup_xml_page = BeautifulSoup(get_xml_page.text, 'xml') # retrieve the content of the page\n",
    "    links = [ link.text for link in soup_xml_page.find_all('loc')] # select the links with loc tag\n",
    "    main_links = [url for url in links if url.find('image') > 0] # select the links to page only\n",
    "len(main_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df8f7b1-17df-46b2-879b-411469f4d3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through the main links to get the image url\n",
    "for pg_url in main_links[0:10]:\n",
    "    get_pg = requests.get(pg_url)\n",
    "    soup_html = BeautifulSoup(get_pg.text, 'html')\n",
    "    img_url = soup_html.find('a', class_='download')['href']\n",
    "    data_list.append({'page':pg_url, 'image':img_url})\n",
    "\n",
    "    # download the image\n",
    "    image = requests.get(img_url)\n",
    "    image_name = f\"{pg_url.split('/')[-1]}-{img_url.split('/')[-1]}\"\n",
    "    with open(f\"images/{image_name}\", 'wb') as file:\n",
    "        file.write(image.content)\n",
    "    \n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583c7f0-a961-4f9f-a7f4-9a992412429a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
